# Gemini 2.0 Flash Lab using Vertex AI

This lab provides a **hands-on introduction** to using the **Gemini API** within **Vertex AI**. The accompanying Jupyter notebook demonstrates how to use the **Vertex AI SDK for Python** to interact with the **Gemini 2.0 Flash model**, showcasing its ability to generate text from various input types including text, images, and videos.

## What This Notebook Covers

- **Setting Up Gemini API Access** using Vertex AI SDK in Python
- **Interacting with Gemini 2.0 Flash (gemini-2.0-flash)**
- **Text Generation from**:
  - Text-only prompts
  - Image + text prompts
  - Video + text prompts
- **Exploring Configuration Options** to customize model responses
- **Testing Multimodal Capabilities** for generative AI tasks

## Gemini Overview

**Gemini** is a family of powerful generative AI models developed by **Google DeepMind**, capable of understanding and generating text, code, images, audio, and video.

### Gemini Model Variants

- **Gemini Pro**

  - Handles complex reasoning across modalities
  - Suitable for summarization, code understanding, and cross-modal analysis

- **Gemini Flash**
  - Optimized for **speed** and **efficiency**
  - Offers **sub-second response times**
  - Enhanced multimodal support including spatial understanding, audio/image output, and tool integration

## Learning Objectives

By completing this lab, you will:

- Use the **Gemini API** via the **Vertex AI SDK for Python**
- Interact with the **Gemini 2.0 Flash** model for generative tasks
- Generate meaningful responses from **text, image, and video inputs**
- Customize output using **model configuration options**

## Prerequisites

- Familiarity with **Python programming**
- Basic understanding of **APIs**
- Ability to run code in **Vertex AI Workbench**
